# Multi-turn Conversation Example Configuration
# This example shows how to continue a conversation with multiple exchanges

# Model settings
model:
  name: microsoft/Phi-4-multimodal-instruct
  cache_dir: "/Users/Benjamin/dev/ssa/models"
  use_4bit: true

# Generation parameters
generation:
  max_new_tokens: 300
  temperature: 0.7
  do_sample: true

# Input settings using multi-turn conversation
input:
  # Multi-turn conversation example
  messages:
    - role: system
      content:
        "You are a knowledgeable programming tutor. Help users learn programming
        concepts with clear explanations and examples."
    - role: user
      content: "What is the difference between a list and a tuple in Python?"
    - role: assistant
      content:
        "Great question! Lists and tuples are both sequence types in Python, but
        they have key differences:\n\n1. **Mutability**: Lists are mutable (can
        be changed), while tuples are immutable (cannot be changed after
        creation).\n2. **Syntax**: Lists use square brackets [], tuples use
        parentheses ().\n3. **Performance**: Tuples are slightly faster for
        accessing elements.\n\nWould you like me to show you some code examples?"
    - role: user
      content:
        "Yes, please show me some practical examples of when to use each one."

  # Audio input (optional)
  audio_path: null

# Audio recording settings
recording:
  enabled: false
  duration: 10.0
  output_path: null
  sample_rate: 16000
  channels: 1

# Device and optimization settings
device:
  use_mps: true
  force_cpu: false
  disable_flash_attention: true
  low_cpu_mem_usage: true

# Logging and output
logging:
  level: "INFO"
  save_results: true
  results_file: "conversation_results.json"

# Hydra settings
defaults:
  - _self_

hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    name: phi4_conversation
