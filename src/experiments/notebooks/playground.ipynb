{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05401f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Benjamin/dev/ssa/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:experiments.utils.inference_models.phi_4_multimodal_instruct:Initializing Phi-4 multimodal inference with model: microsoft/Phi-4-multimodal-instruct\n",
      "INFO:inference_phi_4_multimodal:MPS device available and functional\n",
      "INFO:inference_phi_4_multimodal:Loading model: microsoft/Phi-4-multimodal-instruct\n",
      "INFO:inference_phi_4_multimodal:Using device: mps\n",
      "INFO:inference_phi_4_multimodal:Model cache directory: models\n",
      "WARNING:inference_phi_4_multimodal:4-bit quantization requested but not supported on mps device or bitsandbytes not available - using full precision\n",
      "INFO:inference_phi_4_multimodal:Loading processor...\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-4-multimodal-instruct:\n",
      "- processing_phi4mm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/Users/Benjamin/dev/ssa/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:625: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "INFO:inference_phi_4_multimodal:Loading model config...\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-4-multimodal-instruct:\n",
      "- configuration_phi4mm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "INFO:inference_phi_4_multimodal:Loading model...\n",
      "INFO:inference_phi_4_multimodal:Attempting to patch Phi4MMModel for PEFT compatibility...\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-4-multimodal-instruct:\n",
      "- modeling_phi4mm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "INFO:inference_phi_4_multimodal:Successfully patched Phi4MMModel in module transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm\n",
      "Fetching 3 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:00<00:00, 20.14s/it]\n",
      "Phi4MMModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:create image tower None\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:freeze_img_processor = False\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:learnable separator enabled for hd transform, hd_transform_order = sub_glb\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:create audio processor {'config': {'activation': 'swish', 'activation_checkpointing': {'interval': 1, 'module': 'transformer', 'offload': False}, 'attention_dim': 1024, 'attention_heads': 16, 'batch_norm': False, 'bias_in_glu': True, 'causal': True, 'chunk_size': -1, 'cnn_layer_norm': True, 'conv_activation': 'swish', 'conv_glu_type': 'swish', 'depthwise_multiplier': 1, 'depthwise_seperable_out_channel': 1024, 'dropout_rate': 0.0, 'encoder_embedding_config': {'input_size': 80}, 'ext_pw_kernel_size': 1, 'ext_pw_out_channel': 1024, 'input_layer': 'nemo_conv', 'input_size': 80, 'kernel_size': 3, 'left_chunk': 18, 'linear_units': 1536, 'nemo_conv_settings': {'conv_channels': 1024}, 'num_blocks': 24, 'relative_attention_bias_args': {'t5_bias_max_distance': 500, 'type': 't5'}, 'time_reduction': 8}, 'name': 'cascades'}\n",
      "/Users/Benjamin/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:freeze_audio_processor = False\n",
      "INFO:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:gradient checkpointing enabled for audio processor\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:16<00:00,  5.65s/it]\n",
      "INFO:inference_phi_4_multimodal:Moving model to mps device...\n",
      "INFO:inference_phi_4_multimodal:Model device after loading: mps:0\n",
      "INFO:inference_phi_4_multimodal:Model loaded successfully!\n",
      "INFO:experiments.utils.inference_models.phi_4_multimodal_instruct:Phi-4 multimodal model loaded successfully\n",
      "INFO:experiments.utils.inference_models.phi_4_multimodal_instruct:Transcribing audio: /Users/Benjamin/dev/ssa/data/fluencybank/processed/wav_clips/20f_000_000.wav\n",
      "INFO:inference_phi_4_multimodal:Preparing inputs...\n",
      "INFO:inference_phi_4_multimodal:Formatted prompt: <|system|>You are an expert audio transcriptionist. Transcribe the provided audio accurately.<|end|><|user|><|audio_1|>Please transcribe this audio file accurately.<|end|><|assistant|>...\n",
      "INFO:inference_phi_4_multimodal:Loading audio from: /Users/Benjamin/dev/ssa/data/fluencybank/processed/wav_clips/20f_000_000.wav\n",
      "INFO:inference_phi_4_multimodal:Model device: mps:0, Target device: mps\n",
      "INFO:inference_phi_4_multimodal:Running inference...\n",
      "/Users/Benjamin/dev/ssa/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "WARNING:transformers_modules.microsoft.Phi-4-multimodal-instruct.33e62acdd07cd7d6635badd529aa0a3467bb9c6a.modeling_phi4mm:You are not running the flash-attention implementation, expect numerical differences.\n",
      "INFO:experiments.utils.inference_models.phi_4_multimodal_instruct:Audio transcription completed successfully\n"
     ]
    }
   ],
   "source": [
    "from experiments.utils.inference_models.phi_4_multimodal_instruct import (\n",
    "    Phi4MultimodalASRModel,\n",
    ")\n",
    "\n",
    "model = Phi4MultimodalASRModel()\n",
    "\n",
    "model.load_model()\n",
    "\n",
    "transcription = model.transcribe(\n",
    "    \"/Users/Benjamin/dev/ssa/data/fluencybank/processed/wav_clips/20f_000_000.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166cee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as a text-based AI, I'm unable to listen to or transcribe audio files. However, if you provide me with the text from the audio file, I'd be happy to help transcribe it for you.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
